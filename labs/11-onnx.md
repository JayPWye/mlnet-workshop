# Phase 11: ONNX

In this session, you will learn how to use an object detection ONNX model from Azure Custom Vision inside a .NET application.

## What is Azure Custom Vision?

Azure Custom Vision is a cloud-based service that lets you build, deploy, and export custom deep learning computer vision models. Visit the [Azure Custom Vision](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home) documentation to learn more.

## What is ONNX?

The Open Neural Network Exchange (ONNX) is an open source format for AI models. ONNX supports interoperability between frameworks. This means you can train a model in one of the many popular machine learning frameworks like PyTorch, convert it into ONNX format and consume the ONNX model in a different framework like ML.NET. To learn more, visit the [ONNX website](https://onnx.ai/).

![ONNX Description](https://user-images.githubusercontent.com/46974588/88130578-eaa75300-cba8-11ea-9da6-b1fd90169f8a.png)

## Phase 11.1: Inspect the model

Download the ONNX object detection model and save it anywhere on your computer.

In your browser, open [Netron](https://lutzroeder.github.io/netron/).

In Netron, select **Open Model...** and use the file explorer to import the ONNX model.

A graph appears showing the layers and nodes of your model. Nodes have annotations and metadata which describes the model such as the model format, a short description, inputs and outputs. 

![Netron Azure Custom Vision Object Detection](https://user-images.githubusercontent.com/46974588/88125411-3c49e080-cb9d-11ea-80d8-661bc85cf594.png)

Select the first node in the graph, labeled **data**.

The input for the model is the following:

- *data*: A `float` array of size 3 x 320 x 320 containing the RGB values of a 320px x 320px image.

The output generated by the model contains the following:

![ONNX Azure Custom Vision Outputs](https://user-images.githubusercontent.com/46974588/88129943-525c9e80-cba7-11ea-986d-016cee6b9b9b.png)

- *detected_boxes*: a `float` array of size `n x 4` where `n` is the number of bounding boxes found in the image. The 4 represents the coordinates of two points P1(x1,y1) and P2(x2,y2) for each bounding box found by the model. The first point corresponds to the top-left point of the bounding box and the second point corresponds to the bottom-right point of the bounding box. 

    ![ONNX Azure Custom Vision Detected Boxes](https://user-images.githubusercontent.com/46974588/88129961-57b9e900-cba7-11ea-9b3d-5339336ad851.png)

- *detected_scores*: a `float` array of size `n` where `n` is the number of bounding boxes found in the image.
- *dectected_classes*: a `float` array of size `n` where `n` is the number of bounding boxes found in the image. The model used in this sample detects two classes:
  - 0: CrackedWindshield
  - 1: Dent

## 11.1: Install NuGet packages

First, we need to add a few NuGet packages to the `ONNXConsole` project. 

If you're using Visual Studio, right click on the project name and select **Manage NuGet Dependencies**. Then click the "Browse" tab and search for `Microsoft.ML.OnnxTransformer`. Make sure to install version **1.5.1**.

Alternately if you prefer working from the command line, you can run this command from the *src/ONNXConsole* folder:

```dotnetcli
dotnet add package Microsoft.ML.OnnxTransformer -v 1.5.1
```

Repeat these steps for the `Microsoft.ML.OnnxRuntime` version `1.4.0` and `Microsoft.ML.ImageAnalytics` version `1.5.1`.

### Define model input schema

Open the `Shared` project and create a new class called `ONNXInput.`

Replace the class definition with the following code:

```csharp
public class ONNXInput
{
    public string ImagePath { get; set; }
}
```

## 11.2: Create pipeline

Open the `Program.cs` file in the `ONNXConsole`.

Add the following `using` statements:

```csharp
using Microsoft.ML;
using Shared;
```

Inside the `Main` method, initialize the the `MLContext`.

```csharp
MLContext mlContext = new MLContext();
```

Create a pipeline to load an image and uses the ONNX model to detect objects in the image.

Below the `mlContext`, add the following code:

```csharp
var pipeline =
    mlContext.Transforms.LoadImages("Image", null, "ImagePath")
    .Append(mlContext.Transforms.ResizeImages("ResizedImage", 320, 320, "Image"))
    .Append(mlContext.Transforms.ExtractPixels("data", "ResizedImage"))
    .Append(mlContext.Transforms.ApplyOnnxModel(
        outputColumnNames: new string[] { "detected_boxes", "detected_scores", "detected_classes" },
        inputColumnNames: new string[] { "data" },
        modelFile: @"C:/Users/luquinta.REDMOND/Downloads/BriCompact.ONNX/model.onnx"));
```

This pipeline performs the following steps:

- `LoadImages` takes the path of an image and creates a Bitmap in the `Image` column.
- The model expects a 320px x 320px image. Therefore, the contents of the `Image` column are resized and stored in the `ResizedImage` column.
- Once the image is resized, extract the pixels into a column called `data` using the `ExtractPixels` transform. Notice that the name of the column containing the pixels is `data` because that's the entrypoint of the model.
- Finally, the model is used to detect objects by using `ApplyOnnxModel` transform.

## 11.3: Create and save ML.NET prediction pipeline

Now that you have the pipeline, you can create an ML.NET model that contains all of the preprocessing and scoring transforms. 

Since no training is actually taking place, you can use an empty `IDataView` when fitting the pipeline.

Below your pipeline definition, create an empty IDataView and call `Fit` to create the model.

```csharp
var emptyDV = mlContext.Data.LoadFromEnumerable(new ONNXInput[] { });
var model = pipeline.Fit(emptyIdv);
```

Now that you have a model, save it for later use.

```csharp
mlContext.Model.Save(model, emptyDV.Schema, @"C:/Dev/ONNXModel.zip");
```

## 11.4: Consume the model

At this point, you have taken an ONNX Model from Azure Custom Vision and used it for scoring as part of an ML.NET pipeline. You can take that saved pipeline and use it inside of the web application to detect damage and adjust prices accordingly.

### Install NuGet packages

First, we need to add a few NuGet packages to the `Web` project. 

If you're using Visual Studio, right click on the project name and select **Manage NuGet Dependencies**. Then click the "Browse" tab and search for `Microsoft.ML.OnnxTransformer`. Make sure to install version **1.5.1**.

Alternately if you prefer working from the command line, you can run this command from the *src/ONNXConsole* folder:

```dotnetcli
dotnet add package Microsoft.ML.OnnxTransformer -v 1.5.1
```

Repeat these steps for the `Microsoft.ML.OnnxRuntime` version `1.4.0` and `Microsoft.ML.ImageAnalytics` version `1.5.1`.

### Define model output schema

Open the `Shared` project and create a new class called `ONNXInput.`

Add the following using statements at the top of the file:

```csharp
using Microsoft.ML.Data;
```

Replace the class definition with the following code:

```csharp
public class ONNXOutput
{
    [ColumnName("detected_boxes")]
    public float[] DetectedBoxes { get; set; }

    [ColumnName("detected_scores")]
    public float[] DetectedScores { get; set; }

    [ColumnName("detected_classes")]
    public long[] DetectedClasses{ get; set; }
}
```

### Configure PredictionEnginePool service

The `PredictionEnginePool` is designed for use with dependency injection which is built into ASP.NET Core. As such, you configure it just like you would any other service you want to use throughout your application.

In the *src/Web* project, open the *Startup.cs* file.

Then, in the `ConfigureServices` method, register a `PredictionEnginePool` service. Give it a unique and descriptive name so that you are able to differentiate it from other models and provide the path where you saved your pipeline to.

```csharp
services.AddPredictionEnginePool<ONNXInput, ONNXOutput>().FromFile(modelName:"DamageDetection",filePath:@"C:/Dev/ONNXModel.zip");
```

### Parse model outputs

The current pipeline takes an image and uses the ONNX model to detect damage. However, the outputs of the model still need to be parsed into bounding box objects. To do so, create a service in the web application.

#### Define bounding box schema

Start off by defining the model output schema.

In the *src/Web/Models* directory, create a new class called `BoundingBox` and add the following using statements at the top.

```csharp
using System.Drawing;
```

Then, replace the class definition with the following code:

```csharp
public class BoundingBox
{
    public Dimensions BoxDimensions { get; set; }
    public float Confidence { get; set; }
    public long DamageCategory { get; set; }
}

public class Dimensions
{
    public PointF P1 { get; set; }
    public PointF P2 { get; set; }
    public float Width { get { return P2.X - P1.X; } }
    public float Height { get { return P2.Y - P1.Y; } }
}
```

The outputs form the model, especially the bounding boxes detected have to be mapped to a set of coordinates. The `detected_boxes` column provides the `x` and `y` coordinates for the top-left and bottom-right points of the bounding box. These values are represented as a float because they determine the percentage offset from the origin or top-left corner of the image.

The `Dimensions` class contains the coordinates of the top-left(`P1`) and bottom-right (`P2`) points. Using these points, we can calculate the width and height. 

The `BoundingBox` class encapsulates the dimensions of the bounding box as well as how confident the model is that the bounding box is the assigned damage category.

#### Define damage detection service.

Now that you have define the bounding box, it's time to add the service that will detect the damage in images using the model. 

In the *src/Web/Services*, create a new interface called `IDamageDetectionService` and add the following `using` statements at the top of the file.

```csharp
using System.Collections.Generic;
using System.Drawing;
using Shared;
```

Replace the interface definition with the following code:

```csharp
public interface IDamageDetectionService
{
    IEnumerable<BoundingBox> DetectDamage(ONNXInput input, float threshold);
    Image AnnotateImage(Image image, IEnumerable<BoundingBox> boundingBoxes);
    float CalculateDamageTotalCost(IEnumerable<BoundingBox> boundingBoxes);
}
```

This interface defines three methods to help with detecting damage in images:

- *DetectDamage*: Returns a list of `BoundingBox` objects with confidence greater-than or equal to the provided threshold from the outputs of the registered `DamageDetection` `PredictionEnginePool`.
- *AnnotateImage*: Draws the detected bounding boxes over the provided image.
- *CalculateDamageTotalCost*: Provides the total cost of the damage found on the vehicle.

Now that you have a definition for the service, create a new class called `DamageDetectionService` in the *src/Web/Services* directory to implement the interface.

Add the following `using` statements at the top of the file:

```csharp
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Drawing;
using System.Drawing.Drawing2D;
using System.Drawing.Imaging;
using Microsoft.AspNetCore.Hosting;
using Microsoft.Extensions.ML;
using Shared;
```

Replace the class definition with the following code:

```csharp
public class DamageDetectionService : IDamageDetectionService
{
    private readonly PredictionEnginePool<ONNXInput, ONNXOutput> _damagePredictionEnginePool;

    public DamageDetectionService(PredictionEnginePool<ONNXInput, ONNXOutput> damagePredictionEnginePool)
    {
        _damagePredictionEnginePool = damagePredictionEnginePool;
    }
}
```

The constructor takes the `PredictionEnginePool` service for the `DamageDetection` ONNX model.

Below the constructor, implement the `DetectDamage` method.

```csharp
public IEnumerable<BoundingBox> DetectDamage(ONNXInput input, float threshold)
{
    // Use prediction engine to make predictions
    var modelOutput = _damagePredictionEnginePool.Predict(modelName: "DamageDetection", example: input);

    // Map detected_boxes, detected_scores, detected_classes to BoundingBox objects
    var boxes = modelOutput.DetectedBoxes;
    var boundingBoxes = new List<BoundingBox>();
    for (var i = 0; i < boxes.Length; i += 4)
    {
        var boxIdx = i / 4;
        var boundingBox = new BoundingBox
        {
            BoxDimensions = new Dimensions { P1 = new PointF(boxes[i], boxes[i + 1]), P2 = new PointF(boxes[i + 2], boxes[i + 3]) },
            Confidence = modelOutput.DetectedScores[boxIdx],
            DamageCategory = modelOutput.DetectedClasses[boxIdx]
        };
        boundingBoxes.Add(boundingBox);
    }

    // Return bounding boxes that are at or above the threshold
    var topBoundingBoxes = boundingBoxes.Where(box => box.Confidence >= threshold).OrderByDescending(box => box.Confidence);
    return topBoundingBoxes;
}
```

Then, implement the `AnnotateImage` method:

```csharp
public Image AnnotateImage(Image image, IEnumerable<BoundingBox> boundingBoxes)
{
    using (image)
    {
        var originalImageHeight = image.Height;
        var originalImageWidth = image.Width;
        foreach (var box in boundingBoxes)
        {
            var left = Math.Max(box.BoxDimensions.P1.X * originalImageWidth, 0);
            var top = Math.Max(box.BoxDimensions.P1.Y * originalImageHeight, 0);
            var width = (int)box.BoxDimensions.Width * originalImageWidth;
            var height = (int)box.BoxDimensions.Height * originalImageHeight;

            using (Graphics g = Graphics.FromImage(image))
            {
                g.CompositingQuality = CompositingQuality.HighQuality;
                g.SmoothingMode = SmoothingMode.HighQuality;
                g.InterpolationMode = InterpolationMode.HighQualityBicubic;

                Pen pen = new Pen(Color.Red, 3.2f);

                // Draw bounding box on image
                g.DrawRectangle(pen, left, top, width, height);
            }
        }
        return new Bitmap(image);
    }
}
```

Finally, implement the `CalculateDamageTotalCost` method:

```csharp
public float CalculateDamageTotalCost(IEnumerable<BoundingBox> boundingBoxes)
{
    float total = 0;

    if (boundingBoxes.Count() == 0) return total;

    foreach(var boundingBox in boundingBoxes)
    {
        switch(boundingBox.DamageCategory)
        {

            case 0L: // Cracked windshield
                total += 200;
                break;
            case 1L: // Dent
                total += 100;
                break;
            default:
                break;
        }
    }
    return total;
}
```

If the car has a cracked windshield, the cost of the vehicle drops by $200. If the car has a dent, then the price drops by $100.

#### Use damage detection service

Use the `DamageDetectionService` to detect damage and adjust the price of your car accordingly.

Open the *src/Web/Pages/Index.cshtml.cs* file and add the following `using` statement:

```csharp
using ONNXWebApp.Services;
```

Directly below the `_carModelService` variable definition add the following code:

```csharp
private readonly IDamageDetectionService _damageDetectionService;
```

Replace the constructor with the following code which injects the `IDamageDetectionService`.

```csharp
public IndexModel(IWebHostEnvironment env, ILogger<IndexModel> logger, ICarModelService carFileModelService, IDamageDetectionService damageDetectionService)
{
    _env = env;
    _logger = logger;
    _carModelService = carFileModelService.GetDetails();
    _damageDetectionService = damageDetectionService;
    CarMakeSL = new SelectList(_carModelService, "Id", "Model", default, "Make");
}
```

Replace the `ProcessUploadImageAsync` method with the following code which uses the `IDamageDetection` service to get the bounding boxes and annotate the image.

```csharp
private async Task<IEnumerable<BoundingBox>> ProcessUploadedImageAsync(IFormFile uploadedImage)
{

    using (var ms = new MemoryStream())
    {
        //Copy image to memory stream
        await uploadedImage.CopyToAsync(ms);

        // Resize Image
        var resizedImage = ResizeImage(ms);
        var fileName = Path.Combine(_env.ContentRootPath, "ImageTemp", $"{Guid.NewGuid().ToString()}.jpg");
        resizedImage.Save(fileName, ImageFormat.Jpeg);

        // Create model input
        var imageInput = new ONNXInput
        {
            ImagePath = fileName
        };

        // Detect damage
        var boundingBoxes = _damageDetectionService.DetectDamage(imageInput, 0.7f);
        var annotatedImage = _damageDetectionService.AnnotateImage(resizedImage, boundingBoxes);

        // Save annotated image to stream
        annotatedImage.Save(ms, ImageFormat.Jpeg);

        // Convert image to base64 string
        var base64Image = Convert.ToBase64String(ms.ToArray());
        CarInfo.Base64Image = $"data:image/png;base64,{base64Image}";

        // Return bounding boxes
        return boundingBoxes;
    }
}
```

Finally, replace the `OnPostAsync` method with the following:

```csharp
public void OnPost()
{
    var selectedMakeModel = _carModelService.Where(x => CarModelDetailId == x.Id).FirstOrDefault();

    CarInfo.Make = selectedMakeModel.Make;
    CarInfo.Model = selectedMakeModel.Model;

    ModelInput input = new ModelInput
    {
        Year = (float)CarInfo.Year,
        Mileage = (float)CarInfo.Mileage,
        Make = CarInfo.Make,
        Model = CarInfo.Model
    };

    ModelOutput prediction = _predictionEnginePool.Predict(input);

    CarInfo.Price = prediction.Score;

    if(ImageUpload != null)
    {
        var boundingBoxes = await ProcessUploadedImageAsync(ImageUpload);
        var damageCost = _damageDetectionService.CalculateDamageTotalCost(boundingBoxes);
        CarInfo.Price = CarInfo.Price - damageCost;
        ShowImage = true;
    }
    ShowPrice = true;
}
```

In the snippet above, the information from the `CarInfo` model is taken and a new instance of `ModelInput` is created. Then, the `Predict` function is used to predict the price of a vehicle, given the inputs from the `input` variable. Once a prediction is made, the `Price` property of the `CarInfo` is set to the predicted value.

As an additional step, if an image is uploaded, the `IDamageDetection` service is used to adjust the price of the vehicle if any damage is found.

Then, the price of the car is displayed on screen.

### Run the app

Set the startup project to `Web` and run the application. Fill in the form fields and select **Predict Price**.

![Consume the model in web app](./media/consume-model.png)

Congratulations! You have now used both the price prediction and object detection ONNX models inside your web application.